\cleardoublepage
\singlespacing
\chapter{Conclusion}
\label{c:conclusion}
\doublespacing\nointerlineskip

We introduced RASCO, a reconfigurable fault tolerance system for tracking, managing duplicated WuObjects, or software components where multi-model nodes are assumed in the network.

We also described Strips, a redundancy configuration model, on how they are used in RASCO to achieve consistent views among strip members without any message ordering guarantees.

Then we described algorithms that made this kind of architecture recovery from failures and reconfigure other parts of the network in linear message complexity.

The previous chapters have described the work that has been done on WuKong
platform on the reconfigurable fault tolerance system problem, and the results
that were obtained from experiment. It is useful to reflect on what has been accomplished and place them in the broader context of the more general fault tolerance problem as well as the specific contributions of this work.

\section{Discussion}

We have shown it is possible to design a reconfigurable fault tolerant system without a strong message ordering properties in order to achieve consensus compared to other related works. Strips makes it really easy to describe a component system with redundancy and it scales with complexity as well.

However, RASCO can only handle one failure at a time, since without a distributed locking mechanism, simultaneous failures occurring across the network would put detectors in discordance and causes confusion as they all assume the rest of the network stays the same as before the failure. 

RASCO also could not account for network partitions where a group of nodes could be disconnected from the network for a period of time and then come back as RASCO encourages the system to recovery as quickly as possible given the current events, it leaves no room of tolerance for nodes partitioning away from the network. But given how often those partitioning occurs, it is important to be able to tell from a partition or not, or employ a tolerance period to compensate when the nodes are gone, and revert back when they are back. But in a partition scenario, two partitions of the network could both be thinking each other's dead, therefore both will try to be active and take over the network, this is typically described as the split brain problem in literature. Therefore it is also important that the split brain problem will be prevented when the split occurs.

Heartbeat is a useful heuristic to detect possible failures in a distributed network, however the binary failure model supporting this heuristic is usually too simple in the context of most distributed systems that it usually gives false positive results on the health of the monitored nodes, thus it couldn't detect possible network partition as a result.

As we have stated in previous chapters, this thesis assumed a stateless application where no services need to store any past states, such as a transactional database. 
Support application with services that needs to have states, e.g. databases.



Deployment problem, what to optimize and how to optimize




Fault tolerance policy

When application are getting complex full with features and configurations, 
it is important to have a high level declarative configuration policy language 
to specify the control for features and control of their respective behaviors 
smoothly. I propose a high level policy for fault tolerance that could be
translated to low level application requirements.
